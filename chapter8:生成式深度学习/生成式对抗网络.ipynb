{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN 的简要实现流程如下所示。\n",
    "(1) generator网络将形状为(latent_dim,)的向量映射到形状为(32, 32, 3)的图像。\n",
    "(2) discriminator 网络将形状为 (32, 32, 3) 的图像映射到一个二进制分数，用于评\n",
    "估图像为真的概率。\n",
    "(3) gan 网络将 generator 网络和 discriminator 网络连接在一起： gan(x) = discriminator\n",
    "(generator(x))。生成器将潜在空间向量解码为图像，判别器对这些图像的真实性进\n",
    "行评估，因此这个 gan 网络是将这些潜在向量映射到判别器的评估结果。\n",
    "(4) 我们使用带有“真” /“假”标签的真假图像样本来训练判别器，就和训练普通的图像\n",
    "分类模型一样。\n",
    "(5) 为了训练生成器，我们要使用 gan 模型的损失相对于生成器权重的梯度。这意味着，\n",
    "在每一步都要移动生成器的权重，其移动方向是让判别器更有可能将生成器解码的图像\n",
    "划分为“真”。换句话说，我们训练生成器来欺骗判别器。\n",
    "\n",
    "下面是本节实现 GAN 生成器和判别器时用到的一些技巧。这里并没有列出与 GAN 相关的\n",
    "全部技巧，更多技巧可查阅关于 GAN 的文献。\n",
    " 我们使用 tanh 作为生成器最后一层的激活，而不用 sigmoid，后者在其他类型的模型中\n",
    "更加常见。\n",
    " 我们使用正态分布（高斯分布）对潜在空间中的点进行采样，而不用均匀分布。\n",
    " 随机性能够提高稳健性。训练GAN得到的是一个动态平衡，所以GAN可能以各种方式“卡\n",
    "住”。在训练过程中引入随机性有助于防止出现这种情况。我们通过两种方式引入随机性：\n",
    "一种是在判别器中使用 dropout，另一种是向判别器的标签添加随机噪声。\n",
    " 稀疏的梯度会妨碍 GAN 的训练。在深度学习中，稀疏性通常是我们需要的属性，但在\n",
    "GAN 中并非如此。有两件事情可能导致梯度稀疏：最大池化运算和 ReLU 激活。我们推\n",
    "荐使用步进卷积代替最大池化来进行下采样，还推荐使用 LeakyReLU 层来代替 ReLU 激\n",
    "活。 LeakyReLU 和 ReLU 类似，但它允许较小的负数激活值，从而放宽了稀疏性限制。\n",
    " 在生成的图像中，经常会见到棋盘状伪影，这是由生成器中像素空间的不均匀覆盖导致的\n",
    "（见图 8-17）。为了解决这个问题，每当在生成器和判别器中都使用步进的 Conv2DTranpose\n",
    "或 Conv2D 时，使用的内核大小要能够被步幅大小整除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN生成器网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN判别器网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "                            lr=0.0008,\n",
    "                            clipvalue=1.0,\n",
    "                            decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "        loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对抗网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现GAN的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "现在开始训练。再次强调一下，训练循环的大致流程如下所示。每轮都进行以下操作。\n",
    "(1) 从潜在空间中抽取随机的点（随机噪声）。\n",
    "(2) 利用这个随机噪声用 generator 生成图像。\n",
    "(3) 将生成图像与真实图像混合。\n",
    "(4) 使用这些混合后的图像以及相应的标签（真实图像为“真”，生成图像为“假”）来训练\n",
    "discriminator，如图 8-18 所示。\n",
    "(5) 在潜在空间中随机抽取新的点。\n",
    "(6) 使用这些随机向量以及全部是“真实图像”的标签来训练 gan。这会更新生成器的权重\n",
    "（只更新生成器的权重，因为判别器在 gan 中被冻结），其更新方向是使得判别器能够\n",
    "将生成图像预测为“真实图像”。这个过程是训练生成器去欺骗判别器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gengfeng/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.700756\n",
      "adversarial loss: 0.6949438\n",
      "discriminator loss: 0.74460995\n",
      "adversarial loss: 0.8886694\n",
      "discriminator loss: 0.69181347\n",
      "adversarial loss: 0.80976474\n",
      "discriminator loss: 0.9451052\n",
      "adversarial loss: 0.72260076\n",
      "discriminator loss: 0.69935393\n",
      "adversarial loss: 0.7079772\n",
      "discriminator loss: 0.74927366\n",
      "adversarial loss: 0.91789377\n",
      "discriminator loss: 0.64778435\n",
      "adversarial loss: 0.78957736\n",
      "discriminator loss: 0.67937165\n",
      "adversarial loss: 0.7707585\n",
      "discriminator loss: 0.69006574\n",
      "adversarial loss: 0.7503058\n",
      "discriminator loss: 0.68111503\n",
      "adversarial loss: 0.7335137\n",
      "discriminator loss: 0.69570524\n",
      "adversarial loss: 0.7673322\n",
      "discriminator loss: 0.6885201\n",
      "adversarial loss: 0.7679281\n",
      "discriminator loss: 0.689068\n",
      "adversarial loss: 0.7276888\n",
      "discriminator loss: 0.6881999\n",
      "adversarial loss: 0.75281554\n",
      "discriminator loss: 0.6939681\n",
      "adversarial loss: 0.76283354\n",
      "discriminator loss: 0.7045405\n",
      "adversarial loss: 0.8039566\n",
      "discriminator loss: 0.6990553\n",
      "adversarial loss: 0.7470444\n",
      "discriminator loss: 0.69137716\n",
      "adversarial loss: 0.754374\n",
      "discriminator loss: 0.7071116\n",
      "adversarial loss: 0.716818\n",
      "discriminator loss: 0.6815842\n",
      "adversarial loss: 0.7755634\n",
      "discriminator loss: 0.68964183\n",
      "adversarial loss: 0.73439956\n",
      "discriminator loss: 0.68784\n",
      "adversarial loss: 0.7262439\n",
      "discriminator loss: 1.0489883\n",
      "adversarial loss: 0.79752856\n",
      "discriminator loss: 0.7026893\n",
      "adversarial loss: 0.7328356\n",
      "discriminator loss: 0.77705276\n",
      "adversarial loss: 2.3575854\n",
      "discriminator loss: 0.697557\n",
      "adversarial loss: 0.77350986\n",
      "discriminator loss: 0.6967495\n",
      "adversarial loss: 0.7496983\n",
      "discriminator loss: 0.67814785\n",
      "adversarial loss: 0.850556\n",
      "discriminator loss: 0.68956524\n",
      "adversarial loss: 0.72982275\n",
      "discriminator loss: 0.6834772\n",
      "adversarial loss: 0.7756891\n",
      "discriminator loss: 0.69171745\n",
      "adversarial loss: 0.72573185\n",
      "discriminator loss: 0.7036388\n",
      "adversarial loss: 0.764416\n",
      "discriminator loss: 0.70626193\n",
      "adversarial loss: 0.71948516\n",
      "discriminator loss: 0.69806814\n",
      "adversarial loss: 0.71820724\n",
      "discriminator loss: 0.6794605\n",
      "adversarial loss: 0.77722627\n",
      "discriminator loss: 0.6890856\n",
      "adversarial loss: 0.7506066\n",
      "discriminator loss: 0.67316264\n",
      "adversarial loss: 0.6999516\n",
      "discriminator loss: 0.7453598\n",
      "adversarial loss: 0.74993926\n",
      "discriminator loss: 0.7145823\n",
      "adversarial loss: 0.7721319\n",
      "discriminator loss: 0.7086442\n",
      "adversarial loss: 0.7485469\n",
      "discriminator loss: 0.6943823\n",
      "adversarial loss: 0.769075\n",
      "discriminator loss: 0.68652743\n",
      "adversarial loss: 0.7878154\n",
      "discriminator loss: 0.69297916\n",
      "adversarial loss: 0.77075845\n",
      "discriminator loss: 0.6964569\n",
      "adversarial loss: 0.75543106\n",
      "discriminator loss: 0.68578446\n",
      "adversarial loss: 0.77655506\n",
      "discriminator loss: 0.7012879\n",
      "adversarial loss: 0.7261183\n",
      "discriminator loss: 0.6785576\n",
      "adversarial loss: 0.6500949\n",
      "discriminator loss: 0.69166166\n",
      "adversarial loss: 0.7300844\n",
      "discriminator loss: 0.6951171\n",
      "adversarial loss: 0.7977227\n",
      "discriminator loss: 0.69579124\n",
      "adversarial loss: 0.75340027\n",
      "discriminator loss: 0.7004771\n",
      "adversarial loss: 0.7341977\n",
      "discriminator loss: 0.69092065\n",
      "adversarial loss: 0.79737633\n",
      "discriminator loss: 0.71313494\n",
      "adversarial loss: 0.74452186\n",
      "discriminator loss: 0.6545746\n",
      "adversarial loss: 1.8337891\n",
      "discriminator loss: 0.6832289\n",
      "adversarial loss: 0.8502177\n",
      "discriminator loss: 0.67570984\n",
      "adversarial loss: 0.7249111\n",
      "discriminator loss: 0.7033266\n",
      "adversarial loss: 0.75907826\n",
      "discriminator loss: 0.6901059\n",
      "adversarial loss: 0.75592345\n",
      "discriminator loss: 0.68788654\n",
      "adversarial loss: 0.78456885\n",
      "discriminator loss: 0.7038175\n",
      "adversarial loss: 0.71718574\n",
      "discriminator loss: 0.68368995\n",
      "adversarial loss: 0.76581824\n",
      "discriminator loss: 0.6950017\n",
      "adversarial loss: 0.79863036\n",
      "discriminator loss: 0.6999523\n",
      "adversarial loss: 0.6510928\n",
      "discriminator loss: 0.8591114\n",
      "adversarial loss: 0.95497906\n",
      "discriminator loss: 0.68930066\n",
      "adversarial loss: 0.7217366\n",
      "discriminator loss: 0.7615527\n",
      "adversarial loss: 0.7335915\n",
      "discriminator loss: 0.6928598\n",
      "adversarial loss: 0.65182704\n",
      "discriminator loss: 0.7144375\n",
      "adversarial loss: 0.7705477\n",
      "discriminator loss: 0.6648384\n",
      "adversarial loss: 0.8333341\n",
      "discriminator loss: 0.67920923\n",
      "adversarial loss: 0.7562479\n",
      "discriminator loss: 0.6774313\n",
      "adversarial loss: 0.7425438\n",
      "discriminator loss: 0.6966661\n",
      "adversarial loss: 1.1184573\n",
      "discriminator loss: 0.68794566\n",
      "adversarial loss: 0.9888979\n",
      "discriminator loss: 0.6812161\n",
      "adversarial loss: 0.748226\n",
      "discriminator loss: 0.6951737\n",
      "adversarial loss: 0.7118398\n",
      "discriminator loss: 0.663846\n",
      "adversarial loss: 0.8344016\n",
      "discriminator loss: 0.693257\n",
      "adversarial loss: 0.7769531\n",
      "discriminator loss: 0.67075765\n",
      "adversarial loss: 0.7709925\n",
      "discriminator loss: 0.6953715\n",
      "adversarial loss: 0.75345427\n",
      "discriminator loss: 0.72657746\n",
      "adversarial loss: 1.0699196\n",
      "discriminator loss: 0.6584028\n",
      "adversarial loss: 0.7844187\n",
      "discriminator loss: 0.6617838\n",
      "adversarial loss: 0.6814295\n",
      "discriminator loss: 0.7002273\n",
      "adversarial loss: 0.6924566\n",
      "discriminator loss: 0.6856538\n",
      "adversarial loss: 0.7756677\n",
      "discriminator loss: 0.7503291\n",
      "adversarial loss: 0.76294863\n",
      "discriminator loss: 0.67987716\n",
      "adversarial loss: 0.7802597\n",
      "discriminator loss: 0.6594675\n",
      "adversarial loss: 0.9615366\n",
      "discriminator loss: 0.72459984\n",
      "adversarial loss: 0.7873546\n",
      "discriminator loss: 0.6737696\n",
      "adversarial loss: 0.8525937\n",
      "discriminator loss: 0.692005\n",
      "adversarial loss: 0.727931\n",
      "discriminator loss: 0.6603179\n",
      "adversarial loss: 0.74128735\n",
      "discriminator loss: 0.6590216\n",
      "adversarial loss: 0.7352826\n",
      "discriminator loss: 0.6430211\n",
      "adversarial loss: 0.95333517\n",
      "discriminator loss: 0.680646\n",
      "adversarial loss: 0.80259264\n",
      "discriminator loss: 0.6794874\n",
      "adversarial loss: 0.7868502\n",
      "discriminator loss: 0.6695844\n",
      "adversarial loss: 0.8538001\n",
      "discriminator loss: 0.67397785\n",
      "adversarial loss: 0.9119703\n",
      "discriminator loss: 0.68469554\n",
      "adversarial loss: 0.68902254\n",
      "discriminator loss: 0.67716026\n",
      "adversarial loss: 0.7426325\n",
      "discriminator loss: 0.68460333\n",
      "adversarial loss: 0.7382062\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "x_train = x_train.reshape((x_train.shape[0],) +\n",
    "(height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = './gan/'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
